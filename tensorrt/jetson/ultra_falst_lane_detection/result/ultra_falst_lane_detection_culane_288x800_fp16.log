&&&& RUNNING TensorRT.trtexec [TensorRT v8001] # /usr/src/tensorrt/bin/trtexec --onnx=/home/jetson/tensorrt-examples/models/ultra_falst_lane_detection_culane_288x800.onnx --fp16
[01/19/2022-18:43:13] [I] === Model Options ===
[01/19/2022-18:43:13] [I] Format: ONNX
[01/19/2022-18:43:13] [I] Model: /home/jetson/tensorrt-examples/models/ultra_falst_lane_detection_culane_288x800.onnx
[01/19/2022-18:43:13] [I] Output:
[01/19/2022-18:43:13] [I] === Build Options ===
[01/19/2022-18:43:13] [I] Max batch: explicit
[01/19/2022-18:43:13] [I] Workspace: 16 MiB
[01/19/2022-18:43:13] [I] minTiming: 1
[01/19/2022-18:43:13] [I] avgTiming: 8
[01/19/2022-18:43:13] [I] Precision: FP32+FP16
[01/19/2022-18:43:13] [I] Calibration: 
[01/19/2022-18:43:13] [I] Refit: Disabled
[01/19/2022-18:43:13] [I] Sparsity: Disabled
[01/19/2022-18:43:13] [I] Safe mode: Disabled
[01/19/2022-18:43:13] [I] Restricted mode: Disabled
[01/19/2022-18:43:13] [I] Save engine: 
[01/19/2022-18:43:13] [I] Load engine: 
[01/19/2022-18:43:13] [I] NVTX verbosity: 0
[01/19/2022-18:43:13] [I] Tactic sources: Using default tactic sources
[01/19/2022-18:43:13] [I] timingCacheMode: local
[01/19/2022-18:43:13] [I] timingCacheFile: 
[01/19/2022-18:43:13] [I] Input(s)s format: fp32:CHW
[01/19/2022-18:43:13] [I] Output(s)s format: fp32:CHW
[01/19/2022-18:43:13] [I] Input build shapes: model
[01/19/2022-18:43:13] [I] Input calibration shapes: model
[01/19/2022-18:43:13] [I] === System Options ===
[01/19/2022-18:43:13] [I] Device: 0
[01/19/2022-18:43:13] [I] DLACore: 
[01/19/2022-18:43:13] [I] Plugins:
[01/19/2022-18:43:13] [I] === Inference Options ===
[01/19/2022-18:43:13] [I] Batch: Explicit
[01/19/2022-18:43:13] [I] Input inference shapes: model
[01/19/2022-18:43:13] [I] Iterations: 10
[01/19/2022-18:43:13] [I] Duration: 3s (+ 200ms warm up)
[01/19/2022-18:43:13] [I] Sleep time: 0ms
[01/19/2022-18:43:13] [I] Streams: 1
[01/19/2022-18:43:13] [I] ExposeDMA: Disabled
[01/19/2022-18:43:13] [I] Data transfers: Enabled
[01/19/2022-18:43:13] [I] Spin-wait: Disabled
[01/19/2022-18:43:13] [I] Multithreading: Disabled
[01/19/2022-18:43:13] [I] CUDA Graph: Disabled
[01/19/2022-18:43:13] [I] Separate profiling: Disabled
[01/19/2022-18:43:13] [I] Time Deserialize: Disabled
[01/19/2022-18:43:13] [I] Time Refit: Disabled
[01/19/2022-18:43:13] [I] Skip inference: Disabled
[01/19/2022-18:43:13] [I] Inputs:
[01/19/2022-18:43:13] [I] === Reporting Options ===
[01/19/2022-18:43:13] [I] Verbose: Disabled
[01/19/2022-18:43:13] [I] Averages: 10 inferences
[01/19/2022-18:43:13] [I] Percentile: 99
[01/19/2022-18:43:13] [I] Dump refittable layers:Disabled
[01/19/2022-18:43:13] [I] Dump output: Disabled
[01/19/2022-18:43:13] [I] Profile: Disabled
[01/19/2022-18:43:13] [I] Export timing to JSON file: 
[01/19/2022-18:43:13] [I] Export output to JSON file: 
[01/19/2022-18:43:13] [I] Export profile to JSON file: 
[01/19/2022-18:43:13] [I] 
[01/19/2022-18:43:13] [I] === Device Information ===
[01/19/2022-18:43:13] [I] Selected Device: NVIDIA Tegra X1
[01/19/2022-18:43:13] [I] Compute Capability: 5.3
[01/19/2022-18:43:13] [I] SMs: 1
[01/19/2022-18:43:13] [I] Compute Clock Rate: 0.9216 GHz
[01/19/2022-18:43:13] [I] Device Global Memory: 3956 MiB
[01/19/2022-18:43:13] [I] Shared Memory per SM: 64 KiB
[01/19/2022-18:43:13] [I] Memory Bus Width: 64 bits (ECC disabled)
[01/19/2022-18:43:13] [I] Memory Clock Rate: 0.01275 GHz
[01/19/2022-18:43:13] [I] 
[01/19/2022-18:43:13] [I] TensorRT version: 8001
[01/19/2022-18:43:15] [I] [TRT] [MemUsageChange] Init CUDA: CPU +203, GPU +0, now: CPU 221, GPU 2781 (MiB)
[01/19/2022-18:43:15] [I] Start parsing network model
[01/19/2022-18:43:17] [I] [TRT] ----------------------------------------------------------------
[01/19/2022-18:43:17] [I] [TRT] Input filename:   /home/jetson/tensorrt-examples/models/ultra_falst_lane_detection_culane_288x800.onnx
[01/19/2022-18:43:17] [I] [TRT] ONNX IR version:  0.0.6
[01/19/2022-18:43:17] [I] [TRT] Opset version:    11
[01/19/2022-18:43:17] [I] [TRT] Producer name:    pytorch
[01/19/2022-18:43:17] [I] [TRT] Producer version: 1.9
[01/19/2022-18:43:17] [I] [TRT] Domain:           
[01/19/2022-18:43:17] [I] [TRT] Model version:    0
[01/19/2022-18:43:17] [I] [TRT] Doc string:       
[01/19/2022-18:43:17] [I] [TRT] ----------------------------------------------------------------
[01/19/2022-18:43:18] [01/19/2022-18:43:18] [I] Finish parsing network model
[01/19/2022-18:43:18] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 391, GPU 3136 (MiB)
[01/19/2022-18:43:18] [I] [TRT] [MemUsageSnapshot] Builder begin: CPU 403 MiB, GPU 3165 MiB
[01/19/2022-18:43:18] [I] [TRT] ---------- Layers Running on DLA ----------
[01/19/2022-18:43:18] [I] [TRT] ---------- Layers Running on GPU ----------
[01/19/2022-18:43:18] [I] [TRT] [GpuLayer] Conv_0 + Relu_1
[01/19/2022-18:43:18] [I] [TRT] [GpuLayer] MaxPool_2
[01/19/2022-18:43:18] [I] [TRT] [GpuLayer] Conv_3 + Relu_4
[01/19/2022-18:43:18] [I] [TRT] [GpuLayer] Conv_5 + Add_6 + Relu_7
[01/19/2022-18:43:18] [I] [TRT] [GpuLayer] Conv_8 + Relu_9
[01/19/2022-18:43:18] [I] [TRT] [GpuLayer] Conv_10 + Add_11 + Relu_12
[01/19/2022-18:43:18] [I] [TRT] [GpuLayer] Conv_13 + Relu_14
[01/19/2022-18:43:18] [I] [TRT] [GpuLayer] Conv_16
[01/19/2022-18:43:18] [I] [TRT] [GpuLayer] Conv_15 + Add_17 + Relu_18
[01/19/2022-18:43:18] [I] [TRT] [GpuLayer] Conv_19 + Relu_20
[01/19/2022-18:43:18] [I] [TRT] [GpuLayer] Conv_21 + Add_22 + Relu_23
[01/19/2022-18:43:18] [I] [TRT] [GpuLayer] Conv_24 + Relu_25
[01/19/2022-18:43:18] [I] [TRT] [GpuLayer] Conv_27
[01/19/2022-18:43:18] [I] [TRT] [GpuLayer] Conv_26 + Add_28 + Relu_29
[01/19/2022-18:43:18] [I] [TRT] [GpuLayer] Conv_30 + Relu_31
[01/19/2022-18:43:18] [I] [TRT] [GpuLayer] Conv_32 + Add_33 + Relu_34
[01/19/2022-18:43:18] [I] [TRT] [GpuLayer] Conv_35 + Relu_36
[01/19/2022-18:43:18] [I] [TRT] [GpuLayer] Conv_38
[01/19/2022-18:43:18] [I] [TRT] [GpuLayer] Conv_37 + Add_39 + Relu_40
[01/19/2022-18:43:18] [I] [TRT] [GpuLayer] Conv_41 + Relu_42
[01/19/2022-18:43:18] [I] [TRT] [GpuLayer] Conv_43 + Add_44 + Relu_45
[01/19/2022-18:43:18] [I] [TRT] [GpuLayer] Conv_46
[01/19/2022-18:43:18] [I] [TRT] [GpuLayer] Reshape_48 + (Unnamed Layer* 48) [Shuffle]
[01/19/2022-18:43:18] [I] [TRT] [GpuLayer] Gemm_49 + Relu_50
[01/19/2022-18:43:18] [I] [TRT] [GpuLayer] Gemm_51
[01/19/2022-18:43:18] [I] [TRT] [GpuLayer] (Unnamed Layer* 54) [Shuffle] + Reshape_53
[01/19/2022-18:43:20] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +158, GPU +275, now: CPU 561, GPU 3440 (MiB)
[01/19/2022-18:43:23] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +241, GPU +412, now: CPU 802, GPU 3852 (MiB)
[01/19/2022-18:43:23] [01/19/2022-18:43:35] [I] [TRT] Some tactics do not have sufficient workspace memory to run. Increasing workspace size may increase performance, please check verbose output.
[01/19/2022-18:47:35] [I] [TRT] Detected 1 inputs and 1 output network tensors.
[01/19/2022-18:47:36] [I] [TRT] Total Host Persistent Memory: 34464
[01/19/2022-18:47:36] [I] [TRT] Total Device Persistent Memory: 31158784
[01/19/2022-18:47:36] [I] [TRT] Total Scratch Memory: 0
[01/19/2022-18:47:36] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 169 MiB, GPU 241 MiB
[01/19/2022-18:47:36] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 1137, GPU 3684 (MiB)
[01/19/2022-18:47:36] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +0, now: CPU 1137, GPU 3684 (MiB)
[01/19/2022-18:47:36] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 1137, GPU 3685 (MiB)
[01/19/2022-18:47:36] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 1137, GPU 3685 (MiB)
[01/19/2022-18:47:36] [I] [TRT] [MemUsageSnapshot] Builder end: CPU 1136 MiB, GPU 3685 MiB
[01/19/2022-18:47:37] [I] [TRT] Loaded engine size: 93 MB
[01/19/2022-18:47:37] [I] [TRT] [MemUsageSnapshot] deserializeCudaEngine begin: CPU 1138 MiB, GPU 3640 MiB
[01/19/2022-18:47:38] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 1138, GPU 3640 (MiB)
[01/19/2022-18:47:38] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +0, now: CPU 1138, GPU 3640 (MiB)
[01/19/2022-18:47:38] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 1138, GPU 3640 (MiB)
[01/19/2022-18:47:38] [I] [TRT] [MemUsageSnapshot] deserializeCudaEngine end: CPU 1138 MiB, GPU 3640 MiB
[01/19/2022-18:47:38] [I] Engine built in 264.981 sec.
[01/19/2022-18:47:38] [I] [TRT] [MemUsageSnapshot] ExecutionContext creation begin: CPU 874 MiB, GPU 3392 MiB
[01/19/2022-18:47:38] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 874, GPU 3392 (MiB)
[01/19/2022-18:47:38] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +0, now: CPU 874, GPU 3392 (MiB)
[01/19/2022-18:47:38] [I] [TRT] [MemUsageSnapshot] ExecutionContext creation end: CPU 875 MiB, GPU 3392 MiB
[01/19/2022-18:47:38] [I] Created input binding for input.1 with dimensions 1x3x288x800
[01/19/2022-18:47:38] [I] Created output binding for 200 with dimensions 1x201x18x4
[01/19/2022-18:47:38] [I] Starting inference
[01/19/2022-18:47:41] [I] Warmup completed 4 queries over 200 ms
[01/19/2022-18:47:41] [I] Timing trace has 62 queries over 3.12223 s
[01/19/2022-18:47:41] [I] 
[01/19/2022-18:47:41] [I] === Trace details ===
[01/19/2022-18:47:41] [I] Trace averages of 10 runs:
[01/19/2022-18:47:41] [I] Average on 10 runs - GPU latency: 50.2065 ms - Host latency: 50.4831 ms (end to end 50.4956 ms, enqueue 0.830446 ms)
[01/19/2022-18:47:41] [I] Average on 10 runs - GPU latency: 50.142 ms - Host latency: 50.4185 ms (end to end 50.4313 ms, enqueue 0.831097 ms)
[01/19/2022-18:47:41] [I] Average on 10 runs - GPU latency: 49.9411 ms - Host latency: 50.2181 ms (end to end 50.2309 ms, enqueue 0.814111 ms)
[01/19/2022-18:47:41] [I] Average on 10 runs - GPU latency: 50.071 ms - Host latency: 50.3475 ms (end to end 50.3604 ms, enqueue 0.838635 ms)
[01/19/2022-18:47:41] [I] Average on 10 runs - GPU latency: 50.0962 ms - Host latency: 50.3726 ms (end to end 50.3852 ms, enqueue 0.825806 ms)
[01/19/2022-18:47:41] [I] Average on 10 runs - GPU latency: 49.9944 ms - Host latency: 50.2707 ms (end to end 50.2831 ms, enqueue 0.837378 ms)
[01/19/2022-18:47:41] [I] 
[01/19/2022-18:47:41] [I] === Performance summary ===
[01/19/2022-18:47:41] [I] Throughput: 19.8576 qps
[01/19/2022-18:47:41] [I] Latency: min = 49.9019 ms, max = 50.7354 ms, mean = 50.3454 ms, median = 50.3716 ms, percentile(99%) = 50.7354 ms
[01/19/2022-18:47:41] [I] End-to-End Host Latency: min = 49.9146 ms, max = 50.7477 ms, mean = 50.3579 ms, median = 50.3843 ms, percentile(99%) = 50.7477 ms
[01/19/2022-18:47:41] [I] Enqueue Time: min = 0.786865 ms, max = 0.910645 ms, mean = 0.829756 ms, median = 0.823792 ms, percentile(99%) = 0.910645 ms
[01/19/2022-18:47:41] [I] H2D Latency: min = 0.266602 ms, max = 0.270508 ms, mean = 0.268405 ms, median = 0.268372 ms, percentile(99%) = 0.270508 ms
[01/19/2022-18:47:41] [I] GPU Compute Time: min = 49.626 ms, max = 50.4588 ms, mean = 50.0688 ms, median = 50.0959 ms, percentile(99%) = 50.4588 ms
[01/19/2022-18:47:41] [I] D2H Latency: min = 0.00708008 ms, max = 0.00866699 ms, mean = 0.00810882 ms, median = 0.00805664 ms, percentile(99%) = 0.00866699 ms
[01/19/2022-18:47:41] [I] Total Host Walltime: 3.12223 s
[01/19/2022-18:47:41] [I] Total GPU Compute Time: 3.10427 s
[01/19/2022-18:47:41] [I] Explanations of the performance metrics are printed in the verbose logs.
[01/19/2022-18:47:41] [I] 
&&&& PASSED TensorRT.trtexec [TensorRT v8001] # /usr/src/tensorrt/bin/trtexec --onnx=/home/jetson/tensorrt-examples/models/ultra_falst_lane_detection_culane_288x800.onnx --fp16
[01/19/2022-18:47:41] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 874, GPU 3392 (MiB)
