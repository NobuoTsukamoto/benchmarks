&&&& RUNNING TensorRT.trtexec [TensorRT v8001] # /usr/src/tensorrt/bin/trtexec --onnx=/home/jetson/tensorrt-examples/python/deeplabv3_edgetpuv2/deeplab-edgetpu_default_argmax_xs_opt.onnx
[12/18/2021-12:16:02] [I] === Model Options ===
[12/18/2021-12:16:02] [I] Format: ONNX
[12/18/2021-12:16:02] [I] Model: /home/jetson/tensorrt-examples/python/deeplabv3_edgetpuv2/deeplab-edgetpu_default_argmax_xs_opt.onnx
[12/18/2021-12:16:02] [I] Output:
[12/18/2021-12:16:02] [I] === Build Options ===
[12/18/2021-12:16:02] [I] Max batch: explicit
[12/18/2021-12:16:02] [I] Workspace: 16 MiB
[12/18/2021-12:16:02] [I] minTiming: 1
[12/18/2021-12:16:02] [I] avgTiming: 8
[12/18/2021-12:16:02] [I] Precision: FP32
[12/18/2021-12:16:02] [I] Calibration: 
[12/18/2021-12:16:02] [I] Refit: Disabled
[12/18/2021-12:16:02] [I] Sparsity: Disabled
[12/18/2021-12:16:02] [I] Safe mode: Disabled
[12/18/2021-12:16:02] [I] Restricted mode: Disabled
[12/18/2021-12:16:02] [I] Save engine: 
[12/18/2021-12:16:02] [I] Load engine: 
[12/18/2021-12:16:02] [I] NVTX verbosity: 0
[12/18/2021-12:16:02] [I] Tactic sources: Using default tactic sources
[12/18/2021-12:16:02] [I] timingCacheMode: local
[12/18/2021-12:16:02] [I] timingCacheFile: 
[12/18/2021-12:16:02] [I] Input(s)s format: fp32:CHW
[12/18/2021-12:16:02] [I] Output(s)s format: fp32:CHW
[12/18/2021-12:16:02] [I] Input build shapes: model
[12/18/2021-12:16:02] [I] Input calibration shapes: model
[12/18/2021-12:16:02] [I] === System Options ===
[12/18/2021-12:16:02] [I] Device: 0
[12/18/2021-12:16:02] [I] DLACore: 
[12/18/2021-12:16:02] [I] Plugins:
[12/18/2021-12:16:02] [I] === Inference Options ===
[12/18/2021-12:16:02] [I] Batch: Explicit
[12/18/2021-12:16:02] [I] Input inference shapes: model
[12/18/2021-12:16:02] [I] Iterations: 10
[12/18/2021-12:16:02] [I] Duration: 3s (+ 200ms warm up)
[12/18/2021-12:16:02] [I] Sleep time: 0ms
[12/18/2021-12:16:02] [I] Streams: 1
[12/18/2021-12:16:02] [I] ExposeDMA: Disabled
[12/18/2021-12:16:02] [I] Data transfers: Enabled
[12/18/2021-12:16:02] [I] Spin-wait: Disabled
[12/18/2021-12:16:02] [I] Multithreading: Disabled
[12/18/2021-12:16:02] [I] CUDA Graph: Disabled
[12/18/2021-12:16:02] [I] Separate profiling: Disabled
[12/18/2021-12:16:02] [I] Time Deserialize: Disabled
[12/18/2021-12:16:02] [I] Time Refit: Disabled
[12/18/2021-12:16:02] [I] Skip inference: Disabled
[12/18/2021-12:16:02] [I] Inputs:
[12/18/2021-12:16:02] [I] === Reporting Options ===
[12/18/2021-12:16:02] [I] Verbose: Disabled
[12/18/2021-12:16:02] [I] Averages: 10 inferences
[12/18/2021-12:16:02] [I] Percentile: 99
[12/18/2021-12:16:02] [I] Dump refittable layers:Disabled
[12/18/2021-12:16:02] [I] Dump output: Disabled
[12/18/2021-12:16:02] [I] Profile: Disabled
[12/18/2021-12:16:02] [I] Export timing to JSON file: 
[12/18/2021-12:16:02] [I] Export output to JSON file: 
[12/18/2021-12:16:02] [I] Export profile to JSON file: 
[12/18/2021-12:16:02] [I] 
[12/18/2021-12:16:02] [I] === Device Information ===
[12/18/2021-12:16:02] [I] Selected Device: NVIDIA Tegra X1
[12/18/2021-12:16:02] [I] Compute Capability: 5.3
[12/18/2021-12:16:02] [I] SMs: 1
[12/18/2021-12:16:02] [I] Compute Clock Rate: 0.9216 GHz
[12/18/2021-12:16:02] [I] Device Global Memory: 3956 MiB
[12/18/2021-12:16:02] [I] Shared Memory per SM: 64 KiB
[12/18/2021-12:16:02] [I] Memory Bus Width: 64 bits (ECC disabled)
[12/18/2021-12:16:02] [I] Memory Clock Rate: 0.01275 GHz
[12/18/2021-12:16:02] [I] 
[12/18/2021-12:16:02] [I] TensorRT version: 8001
[12/18/2021-12:16:04] [I] [TRT] [MemUsageChange] Init CUDA: CPU +203, GPU +0, now: CPU 221, GPU 2680 (MiB)
[12/18/2021-12:16:04] [I] Start parsing network model
[12/18/2021-12:16:04] [I] [TRT] ----------------------------------------------------------------
[12/18/2021-12:16:04] [I] [TRT] Input filename:   /home/jetson/tensorrt-examples/python/deeplabv3_edgetpuv2/deeplab-edgetpu_default_argmax_xs_opt.onnx
[12/18/2021-12:16:04] [I] [TRT] ONNX IR version:  0.0.7
[12/18/2021-12:16:04] [I] [TRT] Opset version:    13
[12/18/2021-12:16:04] [I] [TRT] Producer name:    tf2onnx
[12/18/2021-12:16:04] [I] [TRT] Producer version: 1.9.3
[12/18/2021-12:16:04] [I] [TRT] Domain:           
[12/18/2021-12:16:04] [I] [TRT] Model version:    0
[12/18/2021-12:16:04] [I] [TRT] Doc string:       
[12/18/2021-12:16:04] [I] [TRT] ----------------------------------------------------------------
[12/18/2021-12:16:04] [12/18/2021-12:16:04] [12/18/2021-12:16:04] [12/18/2021-12:16:04] [I] Finish parsing network model
[12/18/2021-12:16:04] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 235, GPU 2720 (MiB)
[12/18/2021-12:16:04] [I] [TRT] [MemUsageSnapshot] Builder begin: CPU 246 MiB, GPU 2720 MiB
[12/18/2021-12:16:04] [I] [TRT] ---------- Layers Running on DLA ----------
[12/18/2021-12:16:04] [I] [TRT] ---------- Layers Running on GPU ----------
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/tf.math.multiply_2/Mul/y:0
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] const_fold_opt__495
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/tf.math.multiply_1/Mul/y:0
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] const_fold_opt__499
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/tf.math.multiply/Mul/y:0
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] const_fold_opt__494
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__296 + model/tf.nn.relu/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__297
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__298 + model/tf.nn.relu_1/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__299
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Transpose__300
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/lambda/Split
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/lambda/Split_0
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/conv2d_4/Conv2D__9
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/conv2d_5/Conv2D__11
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__305 + model/tf.nn.relu_2/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__302 + model/tf.nn.relu_3/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__306 + model/tf.math.add_7/Add
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__307 + model/tf.nn.relu_4/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__308
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Transpose__309
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/lambda_1/Split
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/lambda_1/Split_1
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/lambda_1/Split_2
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/conv2d_9/Conv2D__13
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/conv2d_10/Conv2D__15
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/conv2d_11/Conv2D__17
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__317 + model/tf.nn.relu_5/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__316 + model/tf.nn.relu_6/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__311 + model/tf.nn.relu_7/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__318 + model/tf.math.add_14/Add
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__321 + model/tf.nn.relu_8/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__322 + model/tf.math.add_17/Add
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Transpose__324
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/lambda_2/Split
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/lambda_2/Split_3
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/lambda_2/Split_4
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/conv2d_15/Conv2D__21
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/conv2d_16/Conv2D__23
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/conv2d_17/Conv2D__25
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__332 + model/tf.nn.relu_9/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__327 + model/tf.nn.relu_10/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__333 + model/tf.nn.relu_11/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__334 + model/tf.math.add_22/Add
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__335 + model/tf.nn.relu_12/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__336
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__339 + model/tf.nn.relu_13/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__340 + model/tf.nn.relu_14/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__341 + model/tf.math.add_28/Add
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__344 + model/tf.nn.relu_15/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__345 + model/tf.nn.relu_16/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__346 + model/tf.math.add_32/Add
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__349 + model/tf.nn.relu_17/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__350 + model/tf.nn.relu_18/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__351 + model/tf.math.add_36/Add
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__352 + model/tf.nn.relu_19/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__353 + model/tf.nn.relu_20/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__354
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__357 + model/tf.nn.relu_21/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__358 + model/tf.nn.relu_22/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__359 + model/tf.math.add_43/Add
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__362 + model/tf.nn.relu_23/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__363 + model/tf.nn.relu_24/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__364 + model/tf.math.add_47/Add
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__367 + model/tf.nn.relu_25/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__368 + model/tf.nn.relu_26/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__369 + model/tf.math.add_51/Add
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__373 + model/tf.nn.relu_27/Relu || Conv__370 + model/tf.nn.relu_43/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__374 + model/tf.nn.relu_28/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__375
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__378 + model/tf.nn.relu_29/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__379 + model/tf.nn.relu_30/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__380 + model/tf.math.add_58/Add
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__383 + model/tf.nn.relu_31/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__384 + model/tf.nn.relu_32/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__385 + model/tf.math.add_62/Add
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__388 + model/tf.nn.relu_33/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__389 + model/tf.nn.relu_34/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__390 + model/tf.math.add_66/Add
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__391 + model/tf.nn.relu_35/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__392 + model/tf.nn.relu_36/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__393
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/zero_padding2d_25/Pad
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/zero_padding2d_23/Pad
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/zero_padding2d_21/Pad
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/average_pooling2d/AvgPool
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__417 + model/tf.nn.relu_37/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__424 + model/tf.nn.relu_41/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/tf.nn.space_to_depth_4/SpaceToDepth__171 + model/tf.nn.space_to_depth_4/SpaceToDepth
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/tf.nn.space_to_depth_2/SpaceToDepth__194 + model/tf.nn.space_to_depth_2/SpaceToDepth
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/tf.nn.space_to_depth/SpaceToDepth__217 + model/tf.nn.space_to_depth/SpaceToDepth
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] (Unnamed Layer* 132) [Shuffle] + model/depthwise_conv2d_14/depthwise__173
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] (Unnamed Layer* 158) [Shuffle] + model/depthwise_conv2d_13/depthwise__196
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] (Unnamed Layer* 184) [Shuffle] + model/depthwise_conv2d_12/depthwise__219
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Resize__254
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/depthwise_conv2d_14/depthwise
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/depthwise_conv2d_13/depthwise
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/depthwise_conv2d_12/depthwise
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/lambda_7/DepthToSpace__178 + model/lambda_7/DepthToSpace
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/lambda_5/DepthToSpace__201 + model/lambda_5/DepthToSpace
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/lambda_3/DepthToSpace__224 + model/lambda_3/DepthToSpace
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] (Unnamed Layer* 137) [Shuffle]
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] (Unnamed Layer* 163) [Shuffle]
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] (Unnamed Layer* 189) [Shuffle]
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/tf.strided_slice_4/StridedSlice
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/tf.strided_slice_2/StridedSlice
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/tf.strided_slice/StridedSlice
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/zero_padding2d_26/Pad
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/zero_padding2d_24/Pad
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/zero_padding2d_22/Pad
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/tf.nn.space_to_depth_5/SpaceToDepth
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/tf.nn.space_to_depth_3/SpaceToDepth
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/tf.nn.space_to_depth_1/SpaceToDepth
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] (Unnamed Layer* 141) [Shuffle] + model/conv2d_48/Conv2D__186
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] (Unnamed Layer* 167) [Shuffle] + model/conv2d_47/Conv2D__209
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] (Unnamed Layer* 193) [Shuffle] + model/conv2d_46/Conv2D__232
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/conv2d_48/Conv2D
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/conv2d_47/Conv2D
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/conv2d_46/Conv2D
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/lambda_8/DepthToSpace__188 + model/lambda_8/DepthToSpace
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/lambda_6/DepthToSpace__211 + model/lambda_6/DepthToSpace
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/lambda_4/DepthToSpace__234 + model/lambda_4/DepthToSpace
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] (Unnamed Layer* 146) [Shuffle]
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] (Unnamed Layer* 172) [Shuffle]
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] (Unnamed Layer* 198) [Shuffle]
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/tf.strided_slice_5/StridedSlice
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/tf.strided_slice_3/StridedSlice
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/tf.strided_slice_1/StridedSlice
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/lambda_8/DepthToSpace__189
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/lambda_6/DepthToSpace__212
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/lambda_4/DepthToSpace__235
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] PWN(model/tf.math.multiply_2/Mul, model/tf.math.add_79/Add + model/tf.nn.relu_40/Relu)
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] PWN(model/tf.math.multiply_1/Mul, model/tf.math.add_76/Add + model/tf.nn.relu_39/Relu)
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] PWN(model/tf.math.multiply/Mul, model/tf.math.add_73/Add + model/tf.nn.relu_38/Relu)
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Transpose__422
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Transpose__420
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Transpose__418
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Resize__254:0 copy
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__425 + model/tf.nn.relu_42/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Resize__266
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Resize__266:0 copy
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/tf.nn.relu_43/Relu:0 copy
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__426 + model/tf.nn.relu_44/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__427 + model/tf.nn.relu_45/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__428 + model/tf.nn.relu_46/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__429 + model/tf.nn.relu_47/Relu
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Conv__430
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] Resize__294
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/tf.math.reduce_max/Max
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] PWN(const_fold_opt__493, PWN(model/tf.math.subtract/Sub, model/tf.math.minimum/Minimum))
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/tf.math.multiply_3/Mul/y:0 + model/tf.math.multiply_3/Mul + const_fold_opt__475 + model/tf.math.add_88/Add
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/tf.math.reduce_max_1/Max
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] PWN(const_fold_opt__481, model/tf.math.subtract_1/Sub)
[12/18/2021-12:16:04] [I] [TRT] [GpuLayer] model/tf.reshape/Reshape
[12/18/2021-12:16:05] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +158, GPU +159, now: CPU 405, GPU 2879 (MiB)
[12/18/2021-12:16:06] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +241, GPU +242, now: CPU 646, GPU 3121 (MiB)
[12/18/2021-12:16:06] [12/18/2021-12:16:12] [I] [TRT] Some tactics do not have sufficient workspace memory to run. Increasing workspace size may increase performance, please check verbose output.
[12/18/2021-12:25:18] [I] [TRT] Detected 1 inputs and 1 output network tensors.
[12/18/2021-12:25:18] [I] [TRT] Total Host Persistent Memory: 141840
[12/18/2021-12:25:18] [I] [TRT] Total Device Persistent Memory: 15035392
[12/18/2021-12:25:18] [I] [TRT] Total Scratch Memory: 0
[12/18/2021-12:25:18] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 11 MiB, GPU 96 MiB
[12/18/2021-12:25:18] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +1, GPU +0, now: CPU 902, GPU 3352 (MiB)
[12/18/2021-12:25:18] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +0, now: CPU 902, GPU 3352 (MiB)
[12/18/2021-12:25:18] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 902, GPU 3352 (MiB)
[12/18/2021-12:25:18] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 901, GPU 3352 (MiB)
[12/18/2021-12:25:18] [I] [TRT] [MemUsageSnapshot] Builder end: CPU 901 MiB, GPU 3352 MiB
[12/18/2021-12:25:18] [I] [TRT] Loaded engine size: 15 MB
[12/18/2021-12:25:18] [I] [TRT] [MemUsageSnapshot] deserializeCudaEngine begin: CPU 915 MiB, GPU 3368 MiB
[12/18/2021-12:25:18] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 916, GPU 3369 (MiB)
[12/18/2021-12:25:18] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +0, now: CPU 916, GPU 3369 (MiB)
[12/18/2021-12:25:18] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 916, GPU 3369 (MiB)
[12/18/2021-12:25:18] [I] [TRT] [MemUsageSnapshot] deserializeCudaEngine end: CPU 916 MiB, GPU 3369 MiB
[12/18/2021-12:25:18] [I] Engine built in 555.72 sec.
[12/18/2021-12:25:18] [I] [TRT] [MemUsageSnapshot] ExecutionContext creation begin: CPU 886 MiB, GPU 3353 MiB
[12/18/2021-12:25:18] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 886, GPU 3353 (MiB)
[12/18/2021-12:25:18] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU +0, now: CPU 887, GPU 3353 (MiB)
[12/18/2021-12:25:18] [I] [TRT] [MemUsageSnapshot] ExecutionContext creation end: CPU 887 MiB, GPU 3353 MiB
[12/18/2021-12:25:18] [I] Created input binding for inputs with dimensions 1x3x512x512
[12/18/2021-12:25:18] [I] Created output binding for model/tf.reshape/Reshape with dimensions 1x512x512
[12/18/2021-12:25:18] [I] Starting inference
[12/18/2021-12:25:22] [I] Warmup completed 2 queries over 200 ms
[12/18/2021-12:25:22] [I] Timing trace has 30 queries over 3.24882 s
[12/18/2021-12:25:22] [I] 
[12/18/2021-12:25:22] [I] === Trace details ===
[12/18/2021-12:25:22] [I] Trace averages of 10 runs:
[12/18/2021-12:25:22] [I] Average on 10 runs - GPU latency: 108.35 ms - Host latency: 108.762 ms (end to end 108.775 ms, enqueue 4.76936 ms)
[12/18/2021-12:25:22] [I] Average on 10 runs - GPU latency: 107.616 ms - Host latency: 108.029 ms (end to end 108.042 ms, enqueue 4.68147 ms)
[12/18/2021-12:25:22] [I] Average on 10 runs - GPU latency: 107.638 ms - Host latency: 108.051 ms (end to end 108.063 ms, enqueue 4.64495 ms)
[12/18/2021-12:25:22] [I] 
[12/18/2021-12:25:22] [I] === Performance summary ===
[12/18/2021-12:25:22] [I] Throughput: 9.23413 qps
[12/18/2021-12:25:22] [I] Latency: min = 107.448 ms, max = 109.829 ms, mean = 108.281 ms, median = 108.06 ms, percentile(99%) = 109.829 ms
[12/18/2021-12:25:22] [I] End-to-End Host Latency: min = 107.46 ms, max = 109.842 ms, mean = 108.293 ms, median = 108.073 ms, percentile(99%) = 109.842 ms
[12/18/2021-12:25:22] [I] Enqueue Time: min = 4.51733 ms, max = 4.98067 ms, mean = 4.69859 ms, median = 4.69556 ms, percentile(99%) = 4.98067 ms
[12/18/2021-12:25:22] [I] H2D Latency: min = 0.302795 ms, max = 0.306152 ms, mean = 0.304021 ms, median = 0.304199 ms, percentile(99%) = 0.306152 ms
[12/18/2021-12:25:22] [I] GPU Compute Time: min = 107.033 ms, max = 109.416 ms, mean = 107.868 ms, median = 107.646 ms, percentile(99%) = 109.416 ms
[12/18/2021-12:25:22] [I] D2H Latency: min = 0.108032 ms, max = 0.109863 ms, mean = 0.108939 ms, median = 0.108948 ms, percentile(99%) = 0.109863 ms
[12/18/2021-12:25:22] [I] Total Host Walltime: 3.24882 s
[12/18/2021-12:25:22] [I] Total GPU Compute Time: 3.23604 s
[12/18/2021-12:25:22] [I] Explanations of the performance metrics are printed in the verbose logs.
[12/18/2021-12:25:22] [I] 
&&&& PASSED TensorRT.trtexec [TensorRT v8001] # /usr/src/tensorrt/bin/trtexec --onnx=/home/jetson/tensorrt-examples/python/deeplabv3_edgetpuv2/deeplab-edgetpu_default_argmax_xs_opt.onnx
[12/18/2021-12:25:22] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 887, GPU 3354 (MiB)
