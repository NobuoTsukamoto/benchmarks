&&&& RUNNING TensorRT.trtexec [TensorRT v8001] # /usr/src/tensorrt/bin/trtexec --onnx=/home/jetson/tensorrt-examples/python/deeplabv3_edgetpuv2/deeplab-edgetpu_fused_argmax_xs_opt.onnx
[12/18/2021-13:20:49] [I] === Model Options ===
[12/18/2021-13:20:49] [I] Format: ONNX
[12/18/2021-13:20:49] [I] Model: /home/jetson/tensorrt-examples/python/deeplabv3_edgetpuv2/deeplab-edgetpu_fused_argmax_xs_opt.onnx
[12/18/2021-13:20:49] [I] Output:
[12/18/2021-13:20:49] [I] === Build Options ===
[12/18/2021-13:20:49] [I] Max batch: explicit
[12/18/2021-13:20:49] [I] Workspace: 16 MiB
[12/18/2021-13:20:49] [I] minTiming: 1
[12/18/2021-13:20:49] [I] avgTiming: 8
[12/18/2021-13:20:49] [I] Precision: FP32
[12/18/2021-13:20:49] [I] Calibration: 
[12/18/2021-13:20:49] [I] Refit: Disabled
[12/18/2021-13:20:49] [I] Sparsity: Disabled
[12/18/2021-13:20:49] [I] Safe mode: Disabled
[12/18/2021-13:20:49] [I] Restricted mode: Disabled
[12/18/2021-13:20:49] [I] Save engine: 
[12/18/2021-13:20:49] [I] Load engine: 
[12/18/2021-13:20:49] [I] NVTX verbosity: 0
[12/18/2021-13:20:49] [I] Tactic sources: Using default tactic sources
[12/18/2021-13:20:49] [I] timingCacheMode: local
[12/18/2021-13:20:49] [I] timingCacheFile: 
[12/18/2021-13:20:49] [I] Input(s)s format: fp32:CHW
[12/18/2021-13:20:49] [I] Output(s)s format: fp32:CHW
[12/18/2021-13:20:49] [I] Input build shapes: model
[12/18/2021-13:20:49] [I] Input calibration shapes: model
[12/18/2021-13:20:49] [I] === System Options ===
[12/18/2021-13:20:49] [I] Device: 0
[12/18/2021-13:20:49] [I] DLACore: 
[12/18/2021-13:20:49] [I] Plugins:
[12/18/2021-13:20:49] [I] === Inference Options ===
[12/18/2021-13:20:49] [I] Batch: Explicit
[12/18/2021-13:20:49] [I] Input inference shapes: model
[12/18/2021-13:20:49] [I] Iterations: 10
[12/18/2021-13:20:49] [I] Duration: 3s (+ 200ms warm up)
[12/18/2021-13:20:49] [I] Sleep time: 0ms
[12/18/2021-13:20:49] [I] Streams: 1
[12/18/2021-13:20:49] [I] ExposeDMA: Disabled
[12/18/2021-13:20:49] [I] Data transfers: Enabled
[12/18/2021-13:20:49] [I] Spin-wait: Disabled
[12/18/2021-13:20:49] [I] Multithreading: Disabled
[12/18/2021-13:20:49] [I] CUDA Graph: Disabled
[12/18/2021-13:20:49] [I] Separate profiling: Disabled
[12/18/2021-13:20:49] [I] Time Deserialize: Disabled
[12/18/2021-13:20:49] [I] Time Refit: Disabled
[12/18/2021-13:20:49] [I] Skip inference: Disabled
[12/18/2021-13:20:49] [I] Inputs:
[12/18/2021-13:20:49] [I] === Reporting Options ===
[12/18/2021-13:20:49] [I] Verbose: Disabled
[12/18/2021-13:20:49] [I] Averages: 10 inferences
[12/18/2021-13:20:49] [I] Percentile: 99
[12/18/2021-13:20:49] [I] Dump refittable layers:Disabled
[12/18/2021-13:20:49] [I] Dump output: Disabled
[12/18/2021-13:20:49] [I] Profile: Disabled
[12/18/2021-13:20:49] [I] Export timing to JSON file: 
[12/18/2021-13:20:49] [I] Export output to JSON file: 
[12/18/2021-13:20:49] [I] Export profile to JSON file: 
[12/18/2021-13:20:49] [I] 
[12/18/2021-13:20:49] [I] === Device Information ===
[12/18/2021-13:20:49] [I] Selected Device: NVIDIA Tegra X1
[12/18/2021-13:20:49] [I] Compute Capability: 5.3
[12/18/2021-13:20:49] [I] SMs: 1
[12/18/2021-13:20:49] [I] Compute Clock Rate: 0.9216 GHz
[12/18/2021-13:20:49] [I] Device Global Memory: 3956 MiB
[12/18/2021-13:20:49] [I] Shared Memory per SM: 64 KiB
[12/18/2021-13:20:49] [I] Memory Bus Width: 64 bits (ECC disabled)
[12/18/2021-13:20:49] [I] Memory Clock Rate: 0.01275 GHz
[12/18/2021-13:20:49] [I] 
[12/18/2021-13:20:49] [I] TensorRT version: 8001
[12/18/2021-13:20:51] [I] [TRT] [MemUsageChange] Init CUDA: CPU +203, GPU +0, now: CPU 221, GPU 2813 (MiB)
[12/18/2021-13:20:51] [I] Start parsing network model
[12/18/2021-13:20:51] [I] [TRT] ----------------------------------------------------------------
[12/18/2021-13:20:51] [I] [TRT] Input filename:   /home/jetson/tensorrt-examples/python/deeplabv3_edgetpuv2/deeplab-edgetpu_fused_argmax_xs_opt.onnx
[12/18/2021-13:20:51] [I] [TRT] ONNX IR version:  0.0.7
[12/18/2021-13:20:51] [I] [TRT] Opset version:    13
[12/18/2021-13:20:51] [I] [TRT] Producer name:    tf2onnx
[12/18/2021-13:20:51] [I] [TRT] Producer version: 1.9.3
[12/18/2021-13:20:51] [I] [TRT] Domain:           
[12/18/2021-13:20:51] [I] [TRT] Model version:    0
[12/18/2021-13:20:51] [I] [TRT] Doc string:       
[12/18/2021-13:20:51] [I] [TRT] ----------------------------------------------------------------
[12/18/2021-13:20:51] [12/18/2021-13:20:51] [12/18/2021-13:20:51] [12/18/2021-13:20:51] [I] Finish parsing network model
[12/18/2021-13:20:51] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 235, GPU 2852 (MiB)
[12/18/2021-13:20:51] [I] [TRT] [MemUsageSnapshot] Builder begin: CPU 246 MiB, GPU 2852 MiB
[12/18/2021-13:20:51] [I] [TRT] ---------- Layers Running on DLA ----------
[12/18/2021-13:20:51] [I] [TRT] ---------- Layers Running on GPU ----------
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/tf.math.multiply_2/Mul/y:0
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] const_fold_opt__506
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/tf.math.multiply_1/Mul/y:0
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] const_fold_opt__510
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/tf.math.multiply/Mul/y:0
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] const_fold_opt__486
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__306 + model/tf.nn.relu/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__307
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__308 + model/tf.nn.relu_1/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__309
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Transpose__311
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/lambda/Split
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/lambda/Split_0
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/conv2d_4/Conv2D__9
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/conv2d_5/Conv2D__11
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__315 + model/tf.nn.relu_2/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__312 + model/tf.nn.relu_3/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__316 + model/tf.math.add_7/Add
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__317 + model/tf.nn.relu_4/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__318
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Transpose__320
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/lambda_1/Split
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/lambda_1/Split_1
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/lambda_1/Split_2
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/conv2d_9/Conv2D__13
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/conv2d_10/Conv2D__15
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/conv2d_11/Conv2D__17
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__327 + model/tf.nn.relu_5/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__326 + model/tf.nn.relu_6/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__321 + model/tf.nn.relu_7/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__328 + model/tf.math.add_14/Add
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__331 + model/tf.nn.relu_8/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__332 + model/tf.math.add_17/Add
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Transpose__336
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/lambda_2/Split
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/lambda_2/Split_3
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/lambda_2/Split_4
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/conv2d_15/Conv2D__21
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/conv2d_16/Conv2D__23
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/conv2d_17/Conv2D__25
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__342 + model/tf.nn.relu_9/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__337 + model/tf.nn.relu_10/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__343 + model/tf.nn.relu_11/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__344 + model/tf.math.add_22/Add
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__345 + model/tf.nn.relu_12/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__346
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__349 + model/tf.nn.relu_13/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__350 + model/tf.nn.relu_14/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__351 + model/tf.math.add_28/Add
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__354 + model/tf.nn.relu_15/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__355 + model/tf.nn.relu_16/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__356 + model/tf.math.add_32/Add
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__359 + model/tf.nn.relu_17/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__360 + model/tf.nn.relu_18/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__361 + model/tf.math.add_36/Add
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__362 + model/tf.nn.relu_19/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__363 + model/tf.nn.relu_20/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__364
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__367 + model/tf.nn.relu_21/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__368 + model/tf.nn.relu_22/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__369 + model/tf.math.add_43/Add
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__372 + model/tf.nn.relu_23/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__373 + model/tf.nn.relu_24/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__374 + model/tf.math.add_47/Add
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__377 + model/tf.nn.relu_25/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__378 + model/tf.nn.relu_26/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__379 + model/tf.math.add_51/Add
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__383 + model/tf.nn.relu_27/Relu || Conv__380 + model/tf.nn.relu_43/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__384 + model/tf.nn.relu_28/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__385
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__388 + model/tf.nn.relu_29/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__389 + model/tf.nn.relu_30/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__390 + model/tf.math.add_58/Add
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__393 + model/tf.nn.relu_31/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__394 + model/tf.nn.relu_32/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__395 + model/tf.math.add_62/Add
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__398 + model/tf.nn.relu_33/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__399 + model/tf.nn.relu_34/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__400 + model/tf.math.add_66/Add
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__401 + model/tf.nn.relu_35/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__402 + model/tf.nn.relu_36/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__403
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/zero_padding2d_25/Pad
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/zero_padding2d_23/Pad
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/zero_padding2d_21/Pad
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/average_pooling2d/AvgPool
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__427 + model/tf.nn.relu_37/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__434 + model/tf.nn.relu_41/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/tf.nn.space_to_depth_4/SpaceToDepth__171 + model/tf.nn.space_to_depth_4/SpaceToDepth
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/tf.nn.space_to_depth_2/SpaceToDepth__194 + model/tf.nn.space_to_depth_2/SpaceToDepth
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/tf.nn.space_to_depth/SpaceToDepth__217 + model/tf.nn.space_to_depth/SpaceToDepth
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] (Unnamed Layer* 132) [Shuffle] + model/depthwise_conv2d_14/depthwise__173
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] (Unnamed Layer* 158) [Shuffle] + model/depthwise_conv2d_13/depthwise__196
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] (Unnamed Layer* 184) [Shuffle] + model/depthwise_conv2d_12/depthwise__219
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Resize__254
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/depthwise_conv2d_14/depthwise
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/depthwise_conv2d_13/depthwise
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/depthwise_conv2d_12/depthwise
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/lambda_7/DepthToSpace__178 + model/lambda_7/DepthToSpace
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/lambda_5/DepthToSpace__201 + model/lambda_5/DepthToSpace
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/lambda_3/DepthToSpace__224 + model/lambda_3/DepthToSpace
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] (Unnamed Layer* 137) [Shuffle]
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] (Unnamed Layer* 163) [Shuffle]
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] (Unnamed Layer* 189) [Shuffle]
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/tf.strided_slice_4/StridedSlice
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/tf.strided_slice_2/StridedSlice
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/tf.strided_slice/StridedSlice
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/zero_padding2d_26/Pad
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/zero_padding2d_24/Pad
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/zero_padding2d_22/Pad
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/tf.nn.space_to_depth_5/SpaceToDepth
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/tf.nn.space_to_depth_3/SpaceToDepth
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/tf.nn.space_to_depth_1/SpaceToDepth
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] (Unnamed Layer* 141) [Shuffle] + model/conv2d_48/Conv2D__186
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] (Unnamed Layer* 167) [Shuffle] + model/conv2d_47/Conv2D__209
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] (Unnamed Layer* 193) [Shuffle] + model/conv2d_46/Conv2D__232
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/conv2d_48/Conv2D
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/conv2d_47/Conv2D
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/conv2d_46/Conv2D
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/lambda_8/DepthToSpace__188 + model/lambda_8/DepthToSpace
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/lambda_6/DepthToSpace__211 + model/lambda_6/DepthToSpace
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/lambda_4/DepthToSpace__234 + model/lambda_4/DepthToSpace
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] (Unnamed Layer* 146) [Shuffle]
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] (Unnamed Layer* 172) [Shuffle]
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] (Unnamed Layer* 198) [Shuffle]
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/tf.strided_slice_5/StridedSlice
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/tf.strided_slice_3/StridedSlice
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/tf.strided_slice_1/StridedSlice
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/lambda_8/DepthToSpace__189
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/lambda_6/DepthToSpace__212
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/lambda_4/DepthToSpace__235
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] PWN(model/tf.math.multiply_2/Mul, model/tf.math.add_79/Add + model/tf.nn.relu_40/Relu)
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] PWN(model/tf.math.multiply_1/Mul, model/tf.math.add_76/Add + model/tf.nn.relu_39/Relu)
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] PWN(model/tf.math.multiply/Mul, model/tf.math.add_73/Add + model/tf.nn.relu_38/Relu)
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Transpose__432
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Transpose__430
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Transpose__428
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Resize__254:0 copy
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__435 + model/tf.nn.relu_42/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Resize__266
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Resize__266:0 copy
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/tf.nn.relu_43/Relu:0 copy
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__436 + model/tf.nn.relu_44/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__437 + model/tf.nn.relu_45/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__438 + model/tf.nn.relu_46/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__439 + model/tf.nn.relu_47/Relu
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Conv__440
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Resize__294
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/tf.math.reduce_max/Max
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] PWN(model/tf.math.subtract/Sub, PWN(const_fold_opt__480, model/tf.math.minimum/Minimum))
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/tf.math.multiply_3/Mul/y:0 + model/tf.math.multiply_3/Mul + const_fold_opt__508 + model/tf.math.add_88/Add
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/tf.math.reduce_max_1/Max
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] PWN(const_fold_opt__479, model/tf.math.subtract_1/Sub)
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] Resize__304
[12/18/2021-13:20:51] [I] [TRT] [GpuLayer] model/lambda_12/resize/ResizeNearestNeighbor + model/tf.reshape/Reshape
[12/18/2021-13:20:52] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +158, GPU +163, now: CPU 405, GPU 3015 (MiB)
[12/18/2021-13:20:53] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +241, GPU +238, now: CPU 646, GPU 3253 (MiB)
[12/18/2021-13:20:53] [12/18/2021-13:20:59] [I] [TRT] Some tactics do not have sufficient workspace memory to run. Increasing workspace size may increase performance, please check verbose output.
[12/18/2021-13:29:49] [I] [TRT] Detected 1 inputs and 1 output network tensors.
[12/18/2021-13:29:49] [I] [TRT] Total Host Persistent Memory: 137232
[12/18/2021-13:29:49] [I] [TRT] Total Device Persistent Memory: 15035392
[12/18/2021-13:29:49] [I] [TRT] Total Scratch Memory: 0
[12/18/2021-13:29:49] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 11 MiB, GPU 87 MiB
[12/18/2021-13:29:49] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 902, GPU 3527 (MiB)
[12/18/2021-13:29:49] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +0, now: CPU 902, GPU 3527 (MiB)
[12/18/2021-13:29:49] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 902, GPU 3527 (MiB)
[12/18/2021-13:29:49] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 901, GPU 3527 (MiB)
[12/18/2021-13:29:49] [I] [TRT] [MemUsageSnapshot] Builder end: CPU 901 MiB, GPU 3527 MiB
[12/18/2021-13:29:50] [I] [TRT] Loaded engine size: 15 MB
[12/18/2021-13:29:50] [I] [TRT] [MemUsageSnapshot] deserializeCudaEngine begin: CPU 915 MiB, GPU 3543 MiB
[12/18/2021-13:29:50] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 916, GPU 3543 (MiB)
[12/18/2021-13:29:50] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +0, now: CPU 916, GPU 3543 (MiB)
[12/18/2021-13:29:50] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 916, GPU 3543 (MiB)
[12/18/2021-13:29:50] [I] [TRT] [MemUsageSnapshot] deserializeCudaEngine end: CPU 916 MiB, GPU 3543 MiB
[12/18/2021-13:29:50] [I] Engine built in 540.386 sec.
[12/18/2021-13:29:50] [I] [TRT] [MemUsageSnapshot] ExecutionContext creation begin: CPU 887 MiB, GPU 3528 MiB
[12/18/2021-13:29:50] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 887, GPU 3528 (MiB)
[12/18/2021-13:29:50] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +0, now: CPU 887, GPU 3528 (MiB)
[12/18/2021-13:29:50] [I] [TRT] [MemUsageSnapshot] ExecutionContext creation end: CPU 887 MiB, GPU 3528 MiB
[12/18/2021-13:29:50] [I] Created input binding for inputs with dimensions 1x3x512x512
[12/18/2021-13:29:50] [I] Created output binding for model/tf.reshape/Reshape with dimensions 1x512x512
[12/18/2021-13:29:50] [I] Starting inference
[12/18/2021-13:29:53] [I] Warmup completed 3 queries over 200 ms
[12/18/2021-13:29:53] [I] Timing trace has 39 queries over 3.15948 s
[12/18/2021-13:29:53] [I] 
[12/18/2021-13:29:53] [I] === Trace details ===
[12/18/2021-13:29:53] [I] Trace averages of 10 runs:
[12/18/2021-13:29:53] [I] Average on 10 runs - GPU latency: 80.5739 ms - Host latency: 80.9865 ms (end to end 80.999 ms, enqueue 4.7173 ms)
[12/18/2021-13:29:53] [I] Average on 10 runs - GPU latency: 80.7215 ms - Host latency: 81.1344 ms (end to end 81.1467 ms, enqueue 4.72422 ms)
[12/18/2021-13:29:53] [I] Average on 10 runs - GPU latency: 80.5524 ms - Host latency: 80.9649 ms (end to end 80.9775 ms, enqueue 4.72394 ms)
[12/18/2021-13:29:53] [I] 
[12/18/2021-13:29:53] [I] === Performance summary ===
[12/18/2021-13:29:53] [I] Throughput: 12.3438 qps
[12/18/2021-13:29:53] [I] Latency: min = 80.606 ms, max = 81.3967 ms, mean = 80.9994 ms, median = 80.9757 ms, percentile(99%) = 81.3967 ms
[12/18/2021-13:29:53] [I] End-to-End Host Latency: min = 80.614 ms, max = 81.4094 ms, mean = 81.0118 ms, median = 80.9883 ms, percentile(99%) = 81.4094 ms
[12/18/2021-13:29:53] [I] Enqueue Time: min = 4.59406 ms, max = 4.93823 ms, mean = 4.72675 ms, median = 4.70386 ms, percentile(99%) = 4.93823 ms
[12/18/2021-13:29:53] [I] H2D Latency: min = 0.301758 ms, max = 0.305664 ms, mean = 0.303416 ms, median = 0.303345 ms, percentile(99%) = 0.305664 ms
[12/18/2021-13:29:53] [I] GPU Compute Time: min = 80.1941 ms, max = 80.9829 ms, mean = 80.5866 ms, median = 80.562 ms, percentile(99%) = 80.9829 ms
[12/18/2021-13:29:53] [I] D2H Latency: min = 0.10791 ms, max = 0.110107 ms, mean = 0.109375 ms, median = 0.109375 ms, percentile(99%) = 0.110107 ms
[12/18/2021-13:29:53] [I] Total Host Walltime: 3.15948 s
[12/18/2021-13:29:53] [I] Total GPU Compute Time: 3.14288 s
[12/18/2021-13:29:53] [I] Explanations of the performance metrics are printed in the verbose logs.
[12/18/2021-13:29:53] [I] 
&&&& PASSED TensorRT.trtexec [TensorRT v8001] # /usr/src/tensorrt/bin/trtexec --onnx=/home/jetson/tensorrt-examples/python/deeplabv3_edgetpuv2/deeplab-edgetpu_fused_argmax_xs_opt.onnx
[12/18/2021-13:29:53] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 887, GPU 3528 (MiB)
